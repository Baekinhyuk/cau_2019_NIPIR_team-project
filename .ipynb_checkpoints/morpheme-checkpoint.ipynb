{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQCVsQ89Ye5v"
   },
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk\n",
    "!pip3 install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgEgOYaBYoKN"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pNulh_uYoOA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VouV9LUIYoS3"
   },
   "outputs": [],
   "source": [
    "file_list = os.listdir('/content/gdrive/My Drive/IR')\n",
    "\n",
    "def read_data(filename):\n",
    "  with open('/content/gdrive/My Drive/IR/'+filename,'r') as f:\n",
    "    data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "  return data\n",
    "\n",
    "data_dict={'rating1.txt':[],'rating2.txt':[],'rating3.txt':[],'rating4.txt':[],'rating5.txt':[],'rating6.txt':[],'rating7.txt':[],'rating8.txt':[],'rating9.txt':[],'rating10.txt':[]}\n",
    "\n",
    "for file_name in file_list:\n",
    "  data_dict[file_name] = read_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UlQBs1e8YoVQ"
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [''.join(t) for t in okt.morphs(doc)]\n",
    "\n",
    "parsed_docs = {'rating1.txt':[],'rating2.txt':[],'rating3.txt':[],'rating4.txt':[],'rating5.txt':[],'rating6.txt':[],'rating7.txt':[],'rating8.txt':[],'rating9.txt':[],'rating10.txt':[]}\n",
    "\n",
    "for file_name in file_list:\n",
    "  parsed_docs[file_name] = [tokenize(row[0]) for row in data_dict[file_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QikYBuCaYoZr"
   },
   "outputs": [],
   "source": [
    "for file_name in file_list:\n",
    "    with open('/content/gdrive/My Drive/IR/parsed_'+file_name, 'w', encoding=\"utf-8\") as make_file:\n",
    "        for i in range(len(parsed_docs[file_name])):\n",
    "            make_file.write(' '.join(parsed_docs[file_name][i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "morpheme.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
